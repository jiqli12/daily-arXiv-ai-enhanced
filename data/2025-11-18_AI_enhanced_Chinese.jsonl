{"id": "2511.10712", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10712", "abs": "https://arxiv.org/abs/2511.10712", "authors": ["Qinfeng Li", "Miao Pan", "Jintao Chen", "Fu Teng", "Zhiqiang Shen", "Ge Su", "Hao Peng", "Xuhong Zhang"], "title": "Do Not Merge My Model! Safeguarding Open-Source LLMs Against Unauthorized Model Merging", "comment": "Accepted by AAAI 2026 Conference", "summary": "Model merging has emerged as an efficient technique for expanding large language models (LLMs) by integrating specialized expert models. However, it also introduces a new threat: model merging stealing, where free-riders exploit models through unauthorized model merging. Unfortunately, existing defense mechanisms fail to provide effective protection. Specifically, we identify three critical protection properties that existing methods fail to simultaneously satisfy: (1) proactively preventing unauthorized merging; (2) ensuring compatibility with general open-source settings; (3) achieving high security with negligible performance loss. To address the above issues, we propose MergeBarrier, a plug-and-play defense that proactively prevents unauthorized merging. The core design of MergeBarrier is to disrupt the Linear Mode Connectivity (LMC) between the protected model and its homologous counterparts, thereby eliminating the low-loss path required for effective model merging. Extensive experiments show that MergeBarrier effectively prevents model merging stealing with negligible accuracy loss.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMergeBarrier\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7834\u574f\u7ebf\u6027\u6a21\u5f0f\u8fde\u63a5\u6027\u6765\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u6a21\u578b\u5408\u5e76\u7a83\u53d6\uff0c\u5728\u4fdd\u6301\u9ad8\u5b89\u5168\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u5ffd\u7565\u7684\u6027\u80fd\u635f\u5931\u3002", "motivation": "\u6a21\u578b\u5408\u5e76\u6280\u672f\u867d\u7136\u80fd\u9ad8\u6548\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u6a21\u578b\u5408\u5e76\u7a83\u53d6\u7684\u65b0\u5a01\u80c1\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u4e3b\u52a8\u9632\u5fa1\u3001\u5f00\u6e90\u517c\u5bb9\u6027\u548c\u9ad8\u6027\u80fd\u4fdd\u6301\u8fd9\u4e09\u4e2a\u5173\u952e\u4fdd\u62a4\u5c5e\u6027\u3002", "method": "\u63d0\u51faMergeBarrier\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7834\u574f\u4fdd\u62a4\u6a21\u578b\u4e0e\u5176\u540c\u6e90\u6a21\u578b\u4e4b\u95f4\u7684\u7ebf\u6027\u6a21\u5f0f\u8fde\u63a5\u6027\uff0c\u6d88\u9664\u6709\u6548\u6a21\u578b\u5408\u5e76\u6240\u9700\u7684\u4f4e\u635f\u5931\u8def\u5f84\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMergeBarrier\u80fd\u6709\u6548\u9632\u6b62\u6a21\u578b\u5408\u5e76\u7a83\u53d6\uff0c\u540c\u65f6\u4ec5\u5e26\u6765\u53ef\u5ffd\u7565\u7684\u51c6\u786e\u6027\u635f\u5931\u3002", "conclusion": "MergeBarrier\u63d0\u4f9b\u4e86\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u4e3b\u52a8\u9632\u5fa1\u65b9\u6848\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6a21\u578b\u5408\u5e76\u7a83\u53d6\u95ee\u9898\uff0c\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u5173\u952e\u4fdd\u62a4\u8981\u6c42\u3002"}}
{"id": "2511.10714", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10714", "abs": "https://arxiv.org/abs/2511.10714", "authors": ["Shuaitong Liu", "Renjue Li", "Lijia Yu", "Lijun Zhang", "Zhiming Liu", "Gaojie Jin"], "title": "BadThink: Triggered Overthinking Attacks on Chain-of-Thought Reasoning in Large Language Models", "comment": "Accepted at AAAI 2026 (Main Track). This arXiv version corresponds to the camera-ready manuscript and includes expanded appendices. Please cite the AAAI 2026 version when available", "summary": "Recent advances in Chain-of-Thought (CoT) prompting have substantially improved the reasoning capabilities of large language models (LLMs), but have also introduced their computational efficiency as a new attack surface. In this paper, we propose BadThink, the first backdoor attack designed to deliberately induce \"overthinking\" behavior in CoT-enabled LLMs while ensuring stealth. When activated by carefully crafted trigger prompts, BadThink manipulates the model to generate inflated reasoning traces - producing unnecessarily redundant thought processes while preserving the consistency of final outputs. This subtle attack vector creates a covert form of performance degradation that significantly increases computational costs and inference time while remaining difficult to detect through conventional output evaluation methods. We implement this attack through a sophisticated poisoning-based fine-tuning strategy, employing a novel LLM-based iterative optimization process to embed the behavior by generating highly naturalistic poisoned data. Our experiments on multiple state-of-the-art models and reasoning tasks show that BadThink consistently increases reasoning trace lengths - achieving an over 17x increase on the MATH-500 dataset - while remaining stealthy and robust. This work reveals a critical, previously unexplored vulnerability where reasoning efficiency can be covertly manipulated, demonstrating a new class of sophisticated attacks against CoT-enabled systems.", "AI": {"tldr": "BadThink\u662f\u4e00\u79cd\u9488\u5bf9\u601d\u7ef4\u94fe\u63d0\u793a\u7684\u540e\u95e8\u653b\u51fb\uff0c\u901a\u8fc7\u8bf1\u5bfc\u6a21\u578b\u4ea7\u751f\u5197\u4f59\u63a8\u7406\u8fc7\u7a0b\u6765\u589e\u52a0\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u7ec8\u8f93\u51fa\u7684\u6b63\u786e\u6027\uff0c\u4ece\u800c\u9690\u853d\u5730\u964d\u4f4e\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u601d\u7ef4\u94fe\u63d0\u793a\u867d\u7136\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u8ba1\u7b97\u6548\u7387\u8fd9\u4e00\u65b0\u7684\u653b\u51fb\u9762\u3002\u4f5c\u8005\u65e8\u5728\u63ed\u793a\u8fd9\u79cd\u5148\u524d\u672a\u88ab\u63a2\u7d22\u7684\u6f0f\u6d1e\uff0c\u5c55\u793a\u9488\u5bf9CoT\u7cfb\u7edf\u7684\u65b0\u578b\u590d\u6742\u653b\u51fb\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u4e2d\u6bd2\u7684\u5fae\u8c03\u7b56\u7565\u5b9e\u73b0\u653b\u51fb\uff0c\u91c7\u7528\u57fa\u4e8eLLM\u7684\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\u751f\u6210\u9ad8\u5ea6\u81ea\u7136\u7684\u6c61\u67d3\u6570\u636e\uff0c\u5c06\"\u8fc7\u5ea6\u601d\u8003\"\u884c\u4e3a\u5d4c\u5165\u6a21\u578b\u4e2d\u3002", "result": "\u5728\u591a\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBadThink\u80fd\u6301\u7eed\u589e\u52a0\u63a8\u7406\u8f68\u8ff9\u957f\u5ea6\uff0c\u5728MATH-500\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc717\u500d\u7684\u589e\u957f\uff0c\u540c\u65f6\u4fdd\u6301\u9690\u853d\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u63a8\u7406\u6548\u7387\u53ef\u80fd\u88ab\u9690\u853d\u64cd\u7eb5\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u5c55\u793a\u4e86\u4e00\u7c7b\u9488\u5bf9CoT\u7cfb\u7edf\u7684\u65b0\u578b\u590d\u6742\u653b\u51fb\uff0c\u5f3a\u8c03\u4e86\u5728\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65f6\u9700\u8981\u8003\u8651\u7684\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2511.10720", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.10720", "abs": "https://arxiv.org/abs/2511.10720", "authors": ["Runpeng Geng", "Yanting Wang", "Chenlong Yin", "Minhao Cheng", "Ying Chen", "Jinyuan Jia"], "title": "PISanitizer: Preventing Prompt Injection to Long-Context LLMs via Prompt Sanitization", "comment": "The code is available at https://github.com/sleeepeer/PISanitizer", "summary": "Long context LLMs are vulnerable to prompt injection, where an attacker can inject an instruction in a long context to induce an LLM to generate an attacker-desired output. Existing prompt injection defenses are designed for short contexts. When extended to long-context scenarios, they have limited effectiveness. The reason is that an injected instruction constitutes only a very small portion of a long context, making the defense very challenging. In this work, we propose PISanitizer, which first pinpoints and sanitizes potential injected tokens (if any) in a context before letting a backend LLM generate a response, thereby eliminating the influence of the injected instruction. To sanitize injected tokens, PISanitizer builds on two observations: (1) prompt injection attacks essentially craft an instruction that compels an LLM to follow it, and (2) LLMs intrinsically leverage the attention mechanism to focus on crucial input tokens for output generation. Guided by these two observations, we first intentionally let an LLM follow arbitrary instructions in a context and then sanitize tokens receiving high attention that drive the instruction-following behavior of the LLM. By design, PISanitizer presents a dilemma for an attacker: the more effectively an injected instruction compels an LLM to follow it, the more likely it is to be sanitized by PISanitizer. Our extensive evaluation shows that PISanitizer can successfully prevent prompt injection, maintain utility, outperform existing defenses, is efficient, and is robust to optimization-based and strong adaptive attacks. The code is available at https://github.com/sleeepeer/PISanitizer.", "AI": {"tldr": "PISanitizer\u662f\u4e00\u79cd\u9488\u5bf9\u957f\u4e0a\u4e0b\u6587LLM\u7684\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u6e05\u7406\u6f5c\u5728\u6ce8\u5165\u4ee4\u724c\u6765\u6d88\u9664\u653b\u51fb\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u77ed\u4e0a\u4e0b\u6587\u8bbe\u8ba1\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u6ce8\u5165\u6307\u4ee4\u53ea\u5360\u957f\u4e0a\u4e0b\u6587\u5f88\u5c0f\u90e8\u5206\uff0c\u9632\u5fa1\u96be\u5ea6\u5927\u3002", "method": "\u57fa\u4e8e\u4e24\u4e2a\u89c2\u5bdf\uff1a(1)\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u672c\u8d28\u662f\u6784\u5efa\u5f3a\u5236LLM\u9075\u5faa\u7684\u6307\u4ee4\uff1b(2)LLM\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u5173\u6ce8\u5173\u952e\u8f93\u5165\u4ee4\u724c\u3002PISanitizer\u9996\u5148\u8ba9LLM\u9075\u5faa\u4e0a\u4e0b\u6587\u4e2d\u7684\u4efb\u610f\u6307\u4ee4\uff0c\u7136\u540e\u6e05\u7406\u9a71\u52a8\u6307\u4ee4\u9075\u5faa\u884c\u4e3a\u7684\u9ad8\u6ce8\u610f\u529b\u4ee4\u724c\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660ePISanitizer\u80fd\u6210\u529f\u9632\u6b62\u63d0\u793a\u6ce8\u5165\u3001\u4fdd\u6301\u5b9e\u7528\u6027\u3001\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u3001\u6548\u7387\u9ad8\uff0c\u5e76\u5bf9\u57fa\u4e8e\u4f18\u5316\u7684\u5f3a\u81ea\u9002\u5e94\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "PISanitizer\u4e3a\u653b\u51fb\u8005\u5e26\u6765\u56f0\u5883\uff1a\u6ce8\u5165\u6307\u4ee4\u8d8a\u6709\u6548\u5f3a\u5236LLM\u9075\u5faa\uff0c\u5c31\u8d8a\u53ef\u80fd\u88abPISanitizer\u6e05\u7406\uff0c\u4ece\u800c\u6709\u6548\u9632\u5fa1\u957f\u4e0a\u4e0b\u6587LLM\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002"}}
{"id": "2511.10649", "categories": ["cs.MA", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.10649", "abs": "https://arxiv.org/abs/2511.10649", "authors": ["Wojciech Jamroga", "Damian Kurpiewski", "\u0141ukasz Mikulski"], "title": "Towards Assume-Guarantee Verification of Abilities in Stochastic Multi-Agent Systems", "comment": "technical report, work in progress", "summary": "Model checking of strategic abilities is a notoriously hard problem, even more so in the realistic case of agents with imperfect information, acting in a stochastic environment. Assume-guarantee reasoning can be of great help here, providing a way to decompose the complex problem into a small set of easier subproblems.\n  In this paper, we propose several schemes for assume-guarantee verification of probabilistic alternating-time temporal logic with imperfect information. We prove the soundness of the schemes, and discuss their completeness. On the way, we also propose a new variant of (non-probabilistic) alternating-time logic, where the strategic modalities capture \"achieving at most $\\varphi$,\" analogous to Levesque's logic of \"only knowing.\"", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u51e0\u79cd\u7528\u4e8e\u6982\u7387\u4ea4\u66ff\u65f6\u5e8f\u903b\u8f91\u4e0e\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u5047\u8bbe-\u4fdd\u8bc1\u9a8c\u8bc1\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u65b9\u6848\u7684\u6b63\u786e\u6027\u5e76\u8ba8\u8bba\u4e86\u5b8c\u5907\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u975e\u6982\u7387\u4ea4\u66ff\u903b\u8f91\u53d8\u4f53\u3002", "motivation": "\u6218\u7565\u80fd\u529b\u6a21\u578b\u68c0\u67e5\u662f\u4e00\u4e2a\u6781\u5176\u56f0\u96be\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u667a\u80fd\u4f53\u5728\u968f\u673a\u73af\u5883\u4e2d\u884c\u52a8\u7684\u73b0\u5b9e\u60c5\u51b5\u4e0b\u3002\u5047\u8bbe-\u4fdd\u8bc1\u63a8\u7406\u53ef\u4ee5\u5728\u8fd9\u91cc\u63d0\u4f9b\u5f88\u5927\u5e2e\u52a9\uff0c\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u4e00\u5c0f\u7ec4\u66f4\u5bb9\u6613\u7684\u5b50\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u51e0\u79cd\u7528\u4e8e\u6982\u7387\u4ea4\u66ff\u65f6\u5e8f\u903b\u8f91\u4e0e\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u5047\u8bbe-\u4fdd\u8bc1\u9a8c\u8bc1\u65b9\u6848\uff0c\u5e76\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6848\u7684\u6b63\u786e\u6027\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u975e\u6982\u7387\u4ea4\u66ff\u903b\u8f91\u53d8\u4f53\uff0c\u5176\u4e2d\u6218\u7565\u6a21\u6001\u6355\u83b7\"\u81f3\u591a\u5b9e\u73b0\u03c6\"\u7684\u6982\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u9a8c\u8bc1\u65b9\u6848\u7684\u6b63\u786e\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b83\u4eec\u7684\u5b8c\u5907\u6027\u3002\u65b0\u7684\u903b\u8f91\u53d8\u4f53\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u4e8eLevesque\"\u4ec5\u77e5\u9053\"\u903b\u8f91\u7684\u6218\u7565\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "\u5047\u8bbe-\u4fdd\u8bc1\u9a8c\u8bc1\u65b9\u6848\u4e3a\u5904\u7406\u5177\u6709\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u667a\u80fd\u4f53\u5728\u968f\u673a\u73af\u5883\u4e2d\u7684\u6218\u7565\u80fd\u529b\u6a21\u578b\u68c0\u67e5\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5206\u89e3\u65b9\u6cd5\uff0c\u65b0\u7684\u903b\u8f91\u53d8\u4f53\u6269\u5c55\u4e86\u6218\u7565\u6a21\u6001\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2511.10828", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.10828", "abs": "https://arxiv.org/abs/2511.10828", "authors": ["Weiheng Bai", "Kefu Wu", "Qiushi Wu", "Kangjie Lu"], "title": "AFLGopher: Accelerating Directed Fuzzing via Feasibility-Aware Guidance", "comment": null, "summary": "Directed fuzzing is a useful testing technique that aims to efficiently reach target code sites in a program. The core of directed fuzzing is the guiding mechanism that directs the fuzzing to the specified target. A general guiding mechanism adopted in existing directed fuzzers is to calculate the control-flow distance between the current progress and the target, and use that as feedback to guide the directed fuzzing. A fundamental problem with the existing guiding mechanism is that the distance calculation is \\emph{feasibility-unaware}.\n  In this work, we propose feasibility-aware directed fuzzing named AFLGopher. Our new feasibility-aware distance calculation provides pragmatic feedback to guide directed fuzzing to reach targets efficiently. We propose new techniques to address the challenges of feasibility prediction. Our new classification method allows us to predict the feasibility of all branches based on limited traces, and our runtime feasibility-updating mechanism gradually and efficiently improves the prediction precision. We implemented AFLGopher and compared AFLGopher with state-of-the-art directed fuzzers including AFLGo, enhanced AFLGo, WindRanger, BEACON and SelectFuzz. AFLGopher is 3.76x, 2.57x, 3.30x, 2.52x and 2.86x faster than AFLGo, BEACON, WindRanger, SelectFuzz and enhanced AFLGo, respectively, in reaching targets. AFLGopher is 5.60x, 5.20x, 4.98x, 4.52x, and 5.07x faster than AFLGo, BEACON, WindRanger, SelectFuzz and enhanced AFLGo, respectively, in triggering known vulnerabilities.", "AI": {"tldr": "AFLGopher\u662f\u4e00\u79cd\u53ef\u884c\u6027\u611f\u77e5\u7684\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u8ddd\u79bb\u8ba1\u7b97\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5230\u8fbe\u76ee\u6807\u4ee3\u7801\u548c\u89e6\u53d1\u5df2\u77e5\u6f0f\u6d1e\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u7684\u5f15\u5bfc\u673a\u5236\u5728\u8ba1\u7b97\u63a7\u5236\u6d41\u8ddd\u79bb\u65f6\u7f3a\u4e4f\u53ef\u884c\u6027\u611f\u77e5\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u53ef\u884c\u6027\u611f\u77e5\u7684\u8ddd\u79bb\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u6709\u9650\u8f68\u8ff9\u9884\u6d4b\u6240\u6709\u5206\u652f\u53ef\u884c\u6027\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u4ee5\u53ca\u8fd0\u884c\u65f6\u53ef\u884c\u6027\u66f4\u65b0\u673a\u5236\u3002", "result": "AFLGopher\u5728\u5230\u8fbe\u76ee\u6807\u901f\u5ea6\u4e0a\u6bd4\u73b0\u6709\u6700\u4f73\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u5feb2.52-3.76\u500d\uff0c\u5728\u89e6\u53d1\u5df2\u77e5\u6f0f\u6d1e\u4e0a\u5feb4.52-5.60\u500d\u3002", "conclusion": "\u53ef\u884c\u6027\u611f\u77e5\u7684\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u80fd\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\uff0cAFLGopher\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.10687", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.10687", "abs": "https://arxiv.org/abs/2511.10687", "authors": ["Chih-Hsuan Yang", "Tanwi Mallick", "Le Chen", "Krishnan Raghavan", "Azton Wells", "Amal Gueroudji", "Ian T. Foster", "Rajeev Thakur"], "title": "Who Gets the Reward, Who Gets the Blame? Evaluation-Aligned Training Signals for Multi-LLM Agents", "comment": null, "summary": "Large Language Models (LLMs) in multi-agent systems (MAS) have shown promise for complex tasks, yet current training methods lack principled ways to connect system-level evaluation with agent-level and message-level learning. We propose a theoretical framework that unifies cooperative game-theoretic attribution with process reward modeling to transform system evaluation into agent credit and then into response-level signals. Unlike prior approaches that rely only on attribution (e.g., Shapley) or step-level labels (e.g., PRM), our method produces local, signed, and credit-conserving signals. In success cases, Shapley-based credit assignment fairly allocates outcomes across agents and is refined into per-message rewards that promote cooperation while discouraging redundancy or sabotage. In failure cases, first-error localization yields repair-aware preferences that penalize harmful steps while rewarding corrective attempts. The resulting signals are bounded, cooperative, and directly compatible with reinforcement-based or preference-based post-training, providing a unified and auditable pathway from global evaluation to local supervision in LLM multi-agent training. Our contribution is conceptual: we present a theoretical foundation and training signals, leaving empirical validation for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5408\u4f5c\u535a\u5f08\u8bba\u5f52\u56e0\u4e0e\u8fc7\u7a0b\u5956\u52b1\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u5c06\u7cfb\u7edf\u7ea7\u8bc4\u4f30\u8f6c\u5316\u4e3a\u667a\u80fd\u4f53\u4fe1\u7528\u548c\u54cd\u5e94\u7ea7\u4fe1\u53f7\uff0c\u4e3aLLM\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4ece\u5168\u5c40\u8bc4\u4f30\u5230\u5c40\u90e8\u76d1\u7763\u7684\u7edf\u4e00\u8def\u5f84\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2dLLM\u7684\u8bad\u7ec3\u65b9\u6cd5\u7f3a\u4e4f\u5c06\u7cfb\u7edf\u7ea7\u8bc4\u4f30\u4e0e\u667a\u80fd\u4f53\u7ea7\u548c\u6d88\u606f\u7ea7\u5b66\u4e60\u8fde\u63a5\u8d77\u6765\u7684\u539f\u7406\u6027\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u5408\u4f5c\u535a\u5f08\u8bba\u5f52\u56e0\uff08\u5982Shapley\u503c\uff09\u548c\u8fc7\u7a0b\u5956\u52b1\u5efa\u6a21\uff0c\u5728\u6210\u529f\u6848\u4f8b\u4e2d\u57fa\u4e8eShapley\u7684\u4fe1\u7528\u5206\u914d\u516c\u5e73\u5206\u914d\u7ed3\u679c\u5e76\u7ec6\u5316\u4e3a\u6bcf\u6d88\u606f\u5956\u52b1\uff1b\u5728\u5931\u8d25\u6848\u4f8b\u4e2d\u901a\u8fc7\u9996\u6b21\u9519\u8bef\u5b9a\u4f4d\u4ea7\u751f\u4fee\u590d\u611f\u77e5\u504f\u597d\u3002", "result": "\u4ea7\u751f\u7684\u4fe1\u53f7\u5177\u6709\u5c40\u90e8\u6027\u3001\u6709\u7b26\u53f7\u6027\u548c\u4fe1\u7528\u5b88\u6052\u6027\uff0c\u6709\u754c\u3001\u5408\u4f5c\u4e14\u76f4\u63a5\u517c\u5bb9\u57fa\u4e8e\u5f3a\u5316\u6216\u504f\u597d\u7684\u540e\u8bad\u7ec3\u3002", "conclusion": "\u8fd9\u662f\u4e00\u4e2a\u6982\u5ff5\u6027\u8d21\u732e\uff0c\u63d0\u51fa\u4e86\u7406\u8bba\u57fa\u7840\u548c\u8bad\u7ec3\u4fe1\u53f7\uff0c\u4e3aLLM\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u53ef\u5ba1\u8ba1\u7684\u4ece\u5168\u5c40\u8bc4\u4f30\u5230\u5c40\u90e8\u76d1\u7763\u7684\u8def\u5f84\u3002"}}
{"id": "2511.10863", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.10863", "abs": "https://arxiv.org/abs/2511.10863", "authors": ["Yiping Ma", "Yue Guo", "Harish Karthikeyan", "Antigoni Polychroniadou"], "title": "Armadillo: Robust Single-Server Secure Aggregation for Federated Learning with Input Validation", "comment": null, "summary": "This paper presents a secure aggregation system Armadillo that has disruptive resistance against adversarial clients, such that any coalition of malicious clients (within the tolerated threshold) can affect the aggregation result only by misreporting their private inputs in a pre-defined legitimate range. Armadillo is designed for federated learning setting, where a single powerful server interacts with many weak clients iteratively to train models on client's private data. While a few prior works consider disruption resistance under such setting, they either incur high per-client cost (Chowdhury et al. CCS '22) or require many rounds (Bell et al. USENIX Security '23). Although disruption resistance can be achieved generically with zero-knowledge proof techniques (which we also use in this paper), we realize an efficient system with two new designs: 1) a simple two-layer secure aggregation protocol that requires only simple arithmetic computation; 2) an agreement protocol that removes the effect of malicious clients from the aggregation with low round complexity. With these techniques, Armadillo completes each secure aggregation in 3 rounds while keeping the server and clients computationally lightweight.", "AI": {"tldr": "Armadillo\u662f\u4e00\u4e2a\u5177\u6709\u6297\u7834\u574f\u6027\u7684\u5b89\u5168\u805a\u5408\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u62b5\u5fa1\u6076\u610f\u5ba2\u6237\u7aef\u7684\u653b\u51fb\uff0c\u786e\u4fdd\u805a\u5408\u7ed3\u679c\u4ec5\u53d7\u5ba2\u6237\u7aef\u5728\u9884\u5b9a\u4e49\u5408\u6cd5\u8303\u56f4\u5185\u8f93\u5165\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u805a\u5408\u65b9\u6848\u8981\u4e48\u5ba2\u6237\u7aef\u6210\u672c\u9ad8\uff0c\u8981\u4e48\u9700\u8981\u591a\u8f6e\u901a\u4fe1\u3002Armadillo\u65e8\u5728\u5b9e\u73b0\u9ad8\u6548\u3001\u4f4e\u8f6e\u6b21\u7684\u5b89\u5168\u805a\u5408\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u8f7b\u91cf\u7ea7\u3002", "method": "\u91c7\u7528\u4e24\u5c42\u5b89\u5168\u805a\u5408\u534f\u8bae\u548c\u6076\u610f\u5ba2\u6237\u7aef\u6d88\u9664\u534f\u8bae\uff0c\u7ed3\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u6280\u672f\uff0c\u4ec5\u9700\u7b80\u5355\u7b97\u672f\u8ba1\u7b97\u548c3\u8f6e\u901a\u4fe1\u5b8c\u6210\u805a\u5408\u3002", "result": "Armadillo\u5728\u6bcf\u8f6e\u5b89\u5168\u805a\u5408\u4e2d\u4ec5\u97003\u8f6e\u901a\u4fe1\uff0c\u540c\u65f6\u4fdd\u6301\u670d\u52a1\u5668\u548c\u5ba2\u6237\u7aef\u7684\u8ba1\u7b97\u8f7b\u91cf\u7ea7\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u66f4\u9ad8\u6548\u3002", "conclusion": "Armadillo\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u5c42\u805a\u5408\u548c\u6076\u610f\u5ba2\u6237\u7aef\u6d88\u9664\u534f\u8bae\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u8f6e\u6b21\u7684\u5b89\u5168\u805a\u5408\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.10933", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.10933", "abs": "https://arxiv.org/abs/2511.10933", "authors": ["Yunyi Ni", "Ziyu Yang", "Ze Niu", "Emily Davis", "Finn Carter"], "title": "On the Information-Theoretic Fragility of Robust Watermarking under Diffusion Editing", "comment": null, "summary": "Robust invisible watermarking embeds hidden information in images such that the watermark can survive various manipulations. However, the emergence of powerful diffusion-based image generation and editing techniques poses a new threat to these watermarking schemes. In this paper, we investigate the intersection of diffusion-based image editing and robust image watermarking. We analyze how diffusion-driven image edits can significantly degrade or even fully remove embedded watermarks from state-of-the-art robust watermarking systems. Both theoretical formulations and empirical experiments are provided. We prove that as a image undergoes iterative diffusion transformations, the mutual information between the watermarked image and the embedded payload approaches zero, causing watermark decoding to fail. We further propose a guided diffusion attack algorithm that explicitly targets and erases watermark signals during generation. We evaluate our approach on recent deep learning-based watermarking schemes and demonstrate near-zero watermark recovery rates after attack, while maintaining high visual fidelity of the regenerated images. Finally, we discuss ethical implications of such watermark removal capablities and provide design guidelines for future watermarking strategies to be more resilient in the era of generative AI.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6269\u6563\u6a21\u578b\u56fe\u50cf\u7f16\u8f91\u5bf9\u9c81\u68d2\u6c34\u5370\u7684\u5a01\u80c1\uff0c\u8bc1\u660e\u6269\u6563\u53d8\u6362\u4f1a\u4f7f\u6c34\u5370\u4fe1\u606f\u4e22\u5931\uff0c\u5e76\u63d0\u51fa\u9488\u5bf9\u6027\u653b\u51fb\u7b97\u6cd5\uff0c\u80fd\u51e0\u4e4e\u5b8c\u5168\u53bb\u9664\u6c34\u5370\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u6280\u672f\u7684\u51fa\u73b0\uff0c\u4f20\u7edf\u7684\u9c81\u68d2\u6c34\u5370\u65b9\u6848\u9762\u4e34\u65b0\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u4e9b\u65b0\u6280\u672f\u5982\u4f55\u5f71\u54cd\u6c34\u5370\u7684\u751f\u5b58\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7814\u7a76\u6269\u6563\u9a71\u52a8\u7684\u56fe\u50cf\u7f16\u8f91\u5982\u4f55\u964d\u89e3\u6c34\u5370\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u5f15\u5bfc\u6269\u6563\u653b\u51fb\u7b97\u6cd5\uff0c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u660e\u786e\u9488\u5bf9\u5e76\u64e6\u9664\u6c34\u5370\u4fe1\u53f7\u3002", "result": "\u5728\u6700\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6c34\u5370\u65b9\u6848\u4e0a\u8bc4\u4f30\uff0c\u653b\u51fb\u540e\u6c34\u5370\u6062\u590d\u7387\u63a5\u8fd1\u96f6\uff0c\u540c\u65f6\u518d\u751f\u56fe\u50cf\u4fdd\u6301\u9ad8\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u6b64\u7c7b\u6c34\u5370\u53bb\u9664\u80fd\u529b\u7684\u4f26\u7406\u5f71\u54cd\uff0c\u5e76\u4e3a\u672a\u6765\u6c34\u5370\u7b56\u7565\u5728\u751f\u6210AI\u65f6\u4ee3\u63d0\u4f9b\u66f4\u5177\u5f39\u6027\u7684\u8bbe\u8ba1\u6307\u5357\u3002"}}
{"id": "2511.10992", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.10992", "abs": "https://arxiv.org/abs/2511.10992", "authors": ["Jeuk Kang", "Jungheum Park"], "title": "Gynopticon: Consensus-Based Cheating Detection System for Competitive Games", "comment": null, "summary": "Cheating in online games poses significant threats to the gaming industry, yet most prior research has concentrated on Massively Multiplayer Online Role-Playing Games (MMORPGs). Competitive genres-such as Multiplayer Online Battle Arena (MOBA), First Person Shooter (FPS), Real Time Strategy (RTS), and Action games-remain underexplored due to the difficulty of detecting cheating users and the demand for complex data and techniques. To address this gap, many game companies rely on kernel-level anti-cheat solutions, which, while effective, raise serious concerns regarding user privacy and system security. In this paper, we propose GYNOPTICON, a novel cheating detection framework that leverages user consensus to identify abnormal behavior. GYNOPTICON integrates a lightweight client-side detection mechanism with a server-side voting system: when suspicious activity is identified, clients cast votes to the server, which aggregates them to establish consensus and distinguish cheaters from legitimate players. This architecture enables transparency, reduces reliance on intrusive monitoring, and mitigates privacy risks. We evaluate GYNOPTICON in both a controlled simulation and a real-world FPS environment. Simulation results verify its feasibility and requirements, while real-world experiments confirm its effectiveness in reliably detecting cheating users. Furthermore, we demonstrate the system's applicability and sustainability for long-term game management using public datasets. GYNOPTICON represents a user-driven, consensus-based alternative to conventional anti-cheat systems, offering a practical and privacy-preserving solution for competitive online games.", "AI": {"tldr": "GYNOPTICON\u662f\u4e00\u4e2a\u57fa\u4e8e\u7528\u6237\u5171\u8bc6\u7684\u4f5c\u5f0a\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u548c\u670d\u52a1\u5668\u7aef\u6295\u7968\u7cfb\u7edf\u6765\u8bc6\u522b\u6e38\u620f\u4f5c\u5f0a\u884c\u4e3a\uff0c\u4e3a\u7ade\u4e89\u6027\u5728\u7ebf\u6e38\u620f\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u7ade\u4e89\u6027\u6e38\u620f\u7c7b\u578b\uff08\u5982MOBA\u3001FPS\u3001RTS\uff09\u4e2d\u4f5c\u5f0a\u68c0\u6d4b\u7814\u7a76\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u4f20\u7edf\u5185\u6838\u7ea7\u53cd\u4f5c\u5f0a\u65b9\u6848\u5e26\u6765\u7684\u9690\u79c1\u548c\u5b89\u5168\u98ce\u9669\u3002", "method": "\u96c6\u6210\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef\u68c0\u6d4b\u673a\u5236\u548c\u670d\u52a1\u5668\u7aef\u6295\u7968\u7cfb\u7edf\uff1a\u5ba2\u6237\u7aef\u68c0\u6d4b\u53ef\u7591\u6d3b\u52a8\u540e\u5411\u670d\u52a1\u5668\u6295\u7968\uff0c\u670d\u52a1\u5668\u805a\u5408\u6295\u7968\u5efa\u7acb\u5171\u8bc6\u6765\u533a\u5206\u4f5c\u5f0a\u8005\u548c\u5408\u6cd5\u73a9\u5bb6\u3002", "result": "\u5728\u53d7\u63a7\u6a21\u62df\u548c\u771f\u5b9eFPS\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\uff0c\u80fd\u591f\u53ef\u9760\u68c0\u6d4b\u4f5c\u5f0a\u7528\u6237\uff0c\u5e76\u8bc1\u660e\u7cfb\u7edf\u5728\u957f\u671f\u6e38\u620f\u7ba1\u7406\u4e2d\u7684\u9002\u7528\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002", "conclusion": "GYNOPTICON\u4ee3\u8868\u4e86\u4f20\u7edf\u53cd\u4f5c\u5f0a\u7cfb\u7edf\u7684\u7528\u6237\u9a71\u52a8\u3001\u57fa\u4e8e\u5171\u8bc6\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u7ade\u4e89\u6027\u5728\u7ebf\u6e38\u620f\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.11028", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.11028", "abs": "https://arxiv.org/abs/2511.11028", "authors": ["Liu Cao", "Weizheng Wang", "Qipeng Xie", "Dongyu Wei", "Lyutianyang Zhang"], "title": "SALT-V: Lightweight Authentication for 5G V2X Broadcasting", "comment": "This work has been submitted to the IEEE for possible publication. 6 pages, 3 figures", "summary": "Vehicle-to-Everything (V2X) communication faces a critical authentication dilemma: traditional public-key schemes like ECDSA provide strong security but impose 2 ms verification delays unsuitable for collision avoidance, while symmetric approaches like TESLA achieve microsecond-level efficiency at the cost of 20-100 ms key disclosure latency. Neither meets 5G New Radio (NR)-V2X's stringent requirements for both immediate authentication and computational efficiency. This paper presents SALT-V, a novel hybrid authentication framework that reconciles this fundamental trade-off through intelligent protocol stratification. SALT-V employs ECDSA signatures for 10% of traffic (BOOT frames) to establish sender trust, then leverages this trust anchor to authenticate 90% of messages (DATA frames) using lightweight GMAC operations. The core innovation - an Ephemeral Session Tag (EST) whitelist mechanism - enables 95% of messages to achieve immediate verification without waiting for key disclosure, while Bloom filter integration provides O(1) revocation checking in 1 us. Comprehensive evaluation demonstrates that SALT-V achieves 0.035 ms average computation time (57x faster than pure ECDSA), 1 ms end-to-end latency, 41-byte overhead, and linear scalability to 2000 vehicles, making it the first practical solution to satisfy all safety-critical requirements for real-time V2X deployment.", "AI": {"tldr": "SALT-V\u662f\u4e00\u4e2a\u6df7\u5408\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8bae\u5206\u5c42\u89e3\u51b3V2X\u901a\u4fe1\u4e2d\u7684\u8ba4\u8bc1\u56f0\u5883\uff0c\u7ed3\u5408ECDSA\u7684\u5b89\u5168\u6027\u548cGMAC\u7684\u6548\u7387\uff0c\u5b9e\u73b0\u5373\u65f6\u8ba4\u8bc1\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861\u3002", "motivation": "\u4f20\u7edf\u516c\u94a5\u65b9\u6848\uff08\u5982ECDSA\uff09\u9a8c\u8bc1\u5ef6\u8fdf\u9ad8\uff082ms\uff09\u4e0d\u9002\u5408\u9632\u78b0\u649e\uff0c\u5bf9\u79f0\u65b9\u6cd5\uff08\u5982TESLA\uff09\u6548\u7387\u9ad8\u4f46\u5bc6\u94a5\u62ab\u9732\u5ef6\u8fdf\u5927\uff0820-100ms\uff09\uff0c\u90fd\u65e0\u6cd5\u6ee1\u8db35G NR-V2X\u5bf9\u5373\u65f6\u8ba4\u8bc1\u548c\u8ba1\u7b97\u6548\u7387\u7684\u4e25\u683c\u8981\u6c42\u3002", "method": "\u91c7\u7528\u5206\u5c42\u534f\u8bae\uff1a10%\u6d41\u91cf\u4f7f\u7528ECDSA\u7b7e\u540d\uff08BOOT\u5e27\uff09\u5efa\u7acb\u53d1\u9001\u8005\u4fe1\u4efb\uff0c90%\u6d88\u606f\u4f7f\u7528\u8f7b\u91cf\u7ea7GMAC\u64cd\u4f5c\uff08DATA\u5e27\uff09\uff0c\u6838\u5fc3\u521b\u65b0\u662f\u4e34\u65f6\u4f1a\u8bdd\u6807\u7b7e\uff08EST\uff09\u767d\u540d\u5355\u673a\u5236\u548cBloom\u8fc7\u6ee4\u5668\u96c6\u6210\u3002", "result": "\u5e73\u5747\u8ba1\u7b97\u65f6\u95f40.035ms\uff08\u6bd4\u7eafECDSA\u5feb57\u500d\uff09\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf1ms\uff0c\u5f00\u950041\u5b57\u8282\uff0c\u53ef\u7ebf\u6027\u6269\u5c55\u52302000\u8f86\u8f66\uff0c\u6ee1\u8db3\u5b9e\u65f6V2X\u90e8\u7f72\u7684\u6240\u6709\u5b89\u5168\u5173\u952e\u8981\u6c42\u3002", "conclusion": "SALT-V\u662f\u9996\u4e2a\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6ee1\u8db3\u5b9e\u65f6V2X\u90e8\u7f72\u7684\u6240\u6709\u5b89\u5168\u5173\u952e\u8981\u6c42\uff0c\u6210\u529f\u89e3\u51b3\u4e86V2X\u8ba4\u8bc1\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2511.11249", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.11249", "abs": "https://arxiv.org/abs/2511.11249", "authors": ["Melih Co\u015f\u011fun", "Mert Gen\u00e7t\u00fcrk", "Sinem Sav"], "title": "Bridging Local and Federated Data Normalization in Federated Learning: A Privacy-Preserving Approach", "comment": null, "summary": "Data normalization is a crucial preprocessing step for enhancing model performance and training stability. In federated learning (FL), where data remains distributed across multiple parties during collaborative model training, normalization presents unique challenges due to the decentralized and often heterogeneous nature of the data. Traditional methods rely on either independent client-side processing, i.e., local normalization, or normalizing the entire dataset before distributing it to parties, i.e., pooled normalization. Local normalization can be problematic when data distributions across parties are non-IID, while the pooled normalization approach conflicts with the decentralized nature of FL. In this paper, we explore the adaptation of widely used normalization techniques to FL and define the term federated normalization. Federated normalization simulates pooled normalization by enabling the collaborative exchange of normalization parameters among parties. Thus, it achieves performance on par with pooled normalization without compromising data locality. However, sharing normalization parameters such as the mean introduces potential privacy risks, which we further mitigate through a robust privacy-preserving solution. Our contributions include: (i) We systematically evaluate the impact of various federated and local normalization techniques in heterogeneous FL scenarios, (ii) We propose a novel homomorphically encrypted $k$-th ranked element (and median) calculation tailored for the federated setting, enabling secure and efficient federated normalization, (iii) We propose privacy-preserving implementations of widely used normalization techniques for FL, leveraging multiparty fully homomorphic encryption (MHE).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8054\u90a6\u5f52\u4e00\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b89\u5168\u4ea4\u6362\u5f52\u4e00\u5316\u53c2\u6570\u6765\u6a21\u62df\u96c6\u4e2d\u5f0f\u5f52\u4e00\u5316\u7684\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5206\u5e03\u5728\u4e0d\u540c\u5ba2\u6237\u7aef\uff0c\u4f20\u7edf\u672c\u5730\u5f52\u4e00\u5316\u5728\u975eIID\u6570\u636e\u4e0b\u6548\u679c\u5dee\uff0c\u800c\u96c6\u4e2d\u5f0f\u5f52\u4e00\u5316\u8fdd\u80cc\u8054\u90a6\u5b66\u4e60\u7684\u53bb\u4e2d\u5fc3\u5316\u539f\u5219\u3002", "method": "\u63d0\u51fa\u8054\u90a6\u5f52\u4e00\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u540c\u6001\u52a0\u5bc6\u6280\u672f\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u534f\u4f5c\u8ba1\u7b97\u5f52\u4e00\u5316\u53c2\u6570\u3002", "result": "\u8054\u90a6\u5f52\u4e00\u5316\u80fd\u8fbe\u5230\u4e0e\u96c6\u4e2d\u5f0f\u5f52\u4e00\u5316\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4e0d\u7834\u574f\u6570\u636e\u672c\u5730\u6027\u3002", "conclusion": "\u8054\u90a6\u5f52\u4e00\u5316\u662f\u8054\u90a6\u5b66\u4e60\u4e2d\u6709\u6548\u7684\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u80fd\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.11250", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.11250", "abs": "https://arxiv.org/abs/2511.11250", "authors": ["Biagio Boi", "Christian Esposito"], "title": "Prompt Engineering vs. Fine-Tuning for LLM-Based Vulnerability Detection in Solana and Algorand Smart Contracts", "comment": null, "summary": "Smart contracts have emerged as key components within decentralized environments, enabling the automation of transactions through self-executing programs. While these innovations offer significant advantages, they also present potential drawbacks if the smart contract code is not carefully designed and implemented. This paper investigates the capability of large language models (LLMs) to detect OWASP-inspired vulnerabilities in smart contracts beyond the Ethereum Virtual Machine (EVM) ecosystem, focusing specifically on Solana and Algorand. Given the lack of labeled datasets for non-EVM platforms, we design a synthetic dataset of annotated smart contract snippets in Rust (for Solana) and PyTeal (for Algorand), structured around a vulnerability taxonomy derived from OWASP. We evaluate LLMs under three configurations: prompt engineering, fine-tuning, and a hybrid of both, comparing their performance on different vulnerability categories. Experimental results show that prompt engineering achieves general robustness, while fine-tuning improves precision and recall on less semantically rich languages such as TEAL. Additionally, we analyze how the architectural differences of Solana and Algorand influence the manifestation and detectability of vulnerabilities, offering platform-specific mappings that highlight limitations in existing security tooling. Our findings suggest that LLM-based approaches are viable for static vulnerability detection in smart contracts, provided domain-specific data and categorization are integrated into training pipelines.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4bSolana\u548cAlgorand\u667a\u80fd\u5408\u7ea6\u4e2dOWASP\u6f0f\u6d1e\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u3001\u5fae\u8c03\u548c\u6df7\u5408\u65b9\u6cd5\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0\u63d0\u793a\u5de5\u7a0b\u5177\u6709\u901a\u7528\u9c81\u68d2\u6027\uff0c\u800c\u5fae\u8c03\u5728\u8bed\u4e49\u8f83\u5c11\u7684\u8bed\u8a00\u5982TEAL\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u4f5c\u4e3a\u5173\u952e\u7ec4\u4ef6\uff0c\u5982\u679c\u4ee3\u7801\u8bbe\u8ba1\u4e0d\u5f53\u4f1a\u5e26\u6765\u6f5c\u5728\u98ce\u9669\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8EVM\u751f\u6001\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u5bf9\u975eEVM\u5e73\u53f0\uff08\u5982Solana\u548cAlgorand\uff09\u7684\u6f0f\u6d1e\u68c0\u6d4b\u7814\u7a76\u3002", "method": "\u521b\u5efa\u4e86Rust\uff08Solana\uff09\u548cPyTeal\uff08Algorand\uff09\u7684\u5408\u6210\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u57fa\u4e8eOWASP\u6f0f\u6d1e\u5206\u7c7b\u6cd5\u3002\u8bc4\u4f30\u4e86\u4e09\u79cdLLM\u914d\u7f6e\uff1a\u63d0\u793a\u5de5\u7a0b\u3001\u5fae\u8c03\u548c\u6df7\u5408\u65b9\u6cd5\uff0c\u6bd4\u8f83\u5b83\u4eec\u5728\u4e0d\u540c\u6f0f\u6d1e\u7c7b\u522b\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u63d0\u793a\u5de5\u7a0b\u5b9e\u73b0\u4e86\u901a\u7528\u9c81\u68d2\u6027\uff0c\u800c\u5fae\u8c03\u5728\u8bed\u4e49\u8f83\u5c11\u7684\u8bed\u8a00\uff08\u5982TEAL\uff09\u4e0a\u63d0\u9ad8\u4e86\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u3002\u5206\u6790\u4e86Solana\u548cAlgorand\u67b6\u6784\u5dee\u5f02\u5bf9\u6f0f\u6d1e\u8868\u73b0\u548c\u53ef\u68c0\u6d4b\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u667a\u80fd\u5408\u7ea6\u9759\u6001\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u662f\u53ef\u884c\u7684\uff0c\u524d\u63d0\u662f\u5c06\u9886\u57df\u7279\u5b9a\u6570\u636e\u548c\u5206\u7c7b\u6574\u5408\u5230\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2511.11347", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11347", "abs": "https://arxiv.org/abs/2511.11347", "authors": ["Shaowei Guan", "Hin Chi Kwok", "Ngai Fong Law", "Gregor Stiglic", "Vivian Hui"], "title": "Privacy Challenges and Solutions in Retrieval-Augmented Generation-Enhanced LLMs for Healthcare Chatbots: A Review of Applications, Risks, and Future Directions", "comment": "23 pages, 2 figures", "summary": "Retrieval-augmented generation (RAG) has rapidly emerged as a transformative approach for integrating large language models into clinical and biomedical workflows. However, privacy risks, such as protected health information (PHI) exposure, remain inconsistently mitigated. This review provides a thorough analysis of the current landscape of RAG applications in healthcare, including (i) sensitive data type across clinical scenarios, (ii) the associated privacy risks, (iii) current and emerging data-privacy protection mechanisms and (iv) future direction for patient data privacy protection. We synthesize 23 articles on RAG applications in healthcare and systematically analyze privacy challenges through a pipeline-structured framework encompassing data storage, transmission, retrieval and generation stages, delineating potential failure modes, their underlying causes in threat models and system mechanisms, and their practical implications. Building on this analysis, we critically review 17 articles on privacy-preserving strategies for RAG systems. Our evaluation reveals critical gaps, including insufficient clinical validation, absence of standardized evaluation frameworks, and lack of automated assessment tools. We propose actionable directions based on these limitations and conclude with a call to action. This review provides researchers and practitioners with a structured framework for understanding privacy vulnerabilities in healthcare RAG and offers a roadmap toward developing systems that achieve both clinical effectiveness and robust privacy preservation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u533b\u7597\u9886\u57df\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5e94\u7528\u7684\u9690\u79c1\u98ce\u9669\uff0c\u5206\u6790\u4e8623\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u63d0\u51fa\u4e86\u6db5\u76d6\u6570\u636e\u5b58\u50a8\u3001\u4f20\u8f93\u3001\u68c0\u7d22\u548c\u751f\u6210\u9636\u6bb5\u7684\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u5e76\u8bc4\u4f30\u4e8617\u7bc7\u9690\u79c1\u4fdd\u62a4\u7b56\u7565\u6587\u732e\uff0c\u6307\u51fa\u4e86\u4e34\u5e8a\u9a8c\u8bc1\u4e0d\u8db3\u3001\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u7f3a\u5931\u7b49\u5173\u952e\u5dee\u8ddd\u3002", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5728\u4e34\u5e8a\u548c\u751f\u7269\u533b\u5b66\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u53d7\u4fdd\u62a4\u5065\u5eb7\u4fe1\u606f(PHI)\u66b4\u9732\u7b49\u9690\u79c1\u98ce\u9669\u5c1a\u672a\u5f97\u5230\u4e00\u81f4\u7f13\u89e3\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u9690\u79c1\u6311\u6218\u5e76\u63d0\u4f9b\u4fdd\u62a4\u673a\u5236\u3002", "method": "\u901a\u8fc7\u7ba1\u9053\u7ed3\u6784\u5316\u6846\u67b6\u5206\u679023\u7bc7\u533b\u7597RAG\u5e94\u7528\u6587\u732e\uff0c\u6db5\u76d6\u6570\u636e\u5b58\u50a8\u3001\u4f20\u8f93\u3001\u68c0\u7d22\u548c\u751f\u6210\u9636\u6bb5\uff0c\u8bc6\u522b\u6f5c\u5728\u6545\u969c\u6a21\u5f0f\u53ca\u5176\u5728\u5a01\u80c1\u6a21\u578b\u548c\u7cfb\u7edf\u673a\u5236\u4e2d\u7684\u6839\u672c\u539f\u56e0\uff0c\u5e76\u8bc4\u4f3017\u7bc7\u9690\u79c1\u4fdd\u62a4\u7b56\u7565\u6587\u732e\u3002", "result": "\u8bc4\u4f30\u63ed\u793a\u4e86\u5173\u952e\u5dee\u8ddd\uff0c\u5305\u62ec\u4e34\u5e8a\u9a8c\u8bc1\u4e0d\u8db3\u3001\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u7f3a\u5931\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u5de5\u5177\u7f3a\u4e4f\u3002\u63d0\u51fa\u4e86\u57fa\u4e8e\u8fd9\u4e9b\u9650\u5236\u7684\u53ef\u64cd\u4f5c\u65b9\u5411\u3002", "conclusion": "\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u7406\u89e3\u533b\u7597RAG\u9690\u79c1\u6f0f\u6d1e\u7684\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u5e76\u4e3a\u5f00\u53d1\u65e2\u5177\u6709\u4e34\u5e8a\u6709\u6548\u6027\u53c8\u5177\u5907\u5f3a\u5927\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2511.11356", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.11356", "abs": "https://arxiv.org/abs/2511.11356", "authors": ["Yanbo Dai", "Zongjie Li", "Zhenlan Ji", "Shuai Wang"], "title": "SEAL: Subspace-Anchored Watermarks for LLM Ownership", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success across a wide range of natural language processing tasks, demonstrating human-level performance in text generation, reasoning, and question answering. However, training such models requires substantial computational resources, large curated datasets, and sophisticated alignment procedures. As a result, they constitute highly valuable intellectual property (IP) assets that warrant robust protection mechanisms. Existing IP protection approaches suffer from critical limitations. Model fingerprinting techniques can identify model architectures but fail to establish ownership of specific model instances. In contrast, traditional backdoor-based watermarking methods embed behavioral anomalies that can be easily removed through common post-processing operations such as fine-tuning or knowledge distillation.\n  We propose SEAL, a subspace-anchored watermarking framework that embeds multi-bit signatures directly into the model's latent representational space, supporting both white-box and black-box verification scenarios. Our approach leverages model editing techniques to align the hidden representations of selected anchor samples with predefined orthogonal bit vectors. This alignment embeds the watermark while preserving the model's original factual predictions, rendering the watermark functionally harmless and stealthy. We conduct comprehensive experiments on multiple benchmark datasets and six prominent LLMs, comparing SEAL with 11 existing fingerprinting and watermarking methods to demonstrate its superior effectiveness, fidelity, efficiency, and robustness. Furthermore, we evaluate SEAL under potential knowledgeable attacks and show that it maintains strong verification performance even when adversaries possess knowledge of the watermarking mechanism and the embedded signatures.", "AI": {"tldr": "SEAL\u662f\u4e00\u4e2a\u5b50\u7a7a\u95f4\u951a\u5b9a\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u591a\u6bd4\u7279\u7b7e\u540d\u5d4c\u5165\u5230\u6a21\u578b\u7684\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u6765\u4fdd\u62a4LLM\u7684\u77e5\u8bc6\u4ea7\u6743\uff0c\u652f\u6301\u767d\u76d2\u548c\u9ed1\u76d2\u9a8c\u8bc1\uff0c\u5177\u6709\u9ad8\u6709\u6548\u6027\u3001\u4fdd\u771f\u5ea6\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709IP\u4fdd\u62a4\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u6a21\u578b\u6307\u7eb9\u6280\u672f\u53ea\u80fd\u8bc6\u522b\u67b6\u6784\u4e0d\u80fd\u786e\u5b9a\u6240\u6709\u6743\uff0c\u4f20\u7edf\u540e\u95e8\u6c34\u5370\u65b9\u6cd5\u5bb9\u6613\u88ab\u5fae\u8c03\u6216\u77e5\u8bc6\u84b8\u998f\u7b49\u540e\u5904\u7406\u64cd\u4f5c\u79fb\u9664\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u6c34\u5370\u65b9\u6cd5\u6765\u4fdd\u62a4LLM\u7684\u77e5\u8bc6\u4ea7\u6743\u3002", "method": "\u5229\u7528\u6a21\u578b\u7f16\u8f91\u6280\u672f\u5c06\u9009\u5b9a\u951a\u70b9\u6837\u672c\u7684\u9690\u85cf\u8868\u793a\u4e0e\u9884\u5b9a\u4e49\u7684\u6b63\u4ea4\u6bd4\u7279\u5411\u91cf\u5bf9\u9f50\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u539f\u59cb\u4e8b\u5b9e\u9884\u6d4b\u7684\u540c\u65f6\u5d4c\u5165\u6c34\u5370\uff0c\u4f7f\u6c34\u5370\u529f\u80fd\u65e0\u5bb3\u4e14\u9690\u853d\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u516d\u4e2a\u4e3b\u8981LLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSEAL\u76f8\u6bd411\u79cd\u73b0\u6709\u65b9\u6cd5\u5728\u6709\u6548\u6027\u3001\u4fdd\u771f\u5ea6\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u5373\u4f7f\u5728\u5bf9\u624b\u77e5\u9053\u6c34\u5370\u673a\u5236\u548c\u7b7e\u540d\u7684\u60c5\u51b5\u4e0b\u4ecd\u4fdd\u6301\u5f3a\u9a8c\u8bc1\u6027\u80fd\u3002", "conclusion": "SEAL\u6846\u67b6\u4e3aLLM\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u65b9\u6848\uff0c\u901a\u8fc7\u5b50\u7a7a\u95f4\u951a\u5b9a\u6c34\u5370\u6280\u672f\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u6240\u6709\u6743\u9a8c\u8bc1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.11381", "categories": ["cs.CR", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.11381", "abs": "https://arxiv.org/abs/2511.11381", "authors": ["Gioliano de Oliveira Braga", "Pedro Henrique dos Santos Rocha", "Rafael Pimenta de Mattos Paix\u00e3o", "Giovani Hoff da Costa", "Gustavo Cavalcanti Morais", "Louren\u00e7o Alves Pereira J\u00fanior"], "title": "SoK: Security Evaluation of Wi-Fi CSI Biometrics: Attacks, Metrics, and Systemic Weaknesses", "comment": "An improved version will be submitted to Euro S&P 2026, and this paper will be updated in the near future", "summary": "Wi-Fi Channel State Information (CSI) has been repeatedly proposed as a biometric modality, often with reports of high accuracy and operational feasibility. However, the field lacks a consolidated understanding of its security properties, adversarial resilience, and methodological consistency. This Systematization of Knowledge (SoK) examines CSI-based biometric authentication through a security perspective, analyzing how existing work differs across sensing infrastructure, signal representations, feature pipelines, learning models, and evaluation methodologies. Our synthesis reveals systemic inconsistencies: reliance on aggregate accuracy metrics, limited reporting of FAR/FRR/EER, absence of per-user risk analysis, and scarce consideration of threat models or adversarial feasibility. We construct a unified evaluation framework to empirically expose these issues and demonstrate how security-relevant metrics, such as per-class EER, FCS, and the Gini Coefficient, uncover risk concentration that remains hidden under traditional reporting practices. Our analysis highlights concrete attack surfaces and shows how methodological choices materially influence vulnerability profiles, which include replay, geometric mimicry, and environmental perturbation. Based on these findings, we articulate the security boundaries of current CSI biometrics and provide guidelines for rigorous evaluation, reproducible experimentation, and future research directions. This SoK offers the security community a structured, evidence-driven reassessment of Wi-Fi CSI biometrics and their suitability as an authentication primitive.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5316\u5206\u6790\u4e86Wi-Fi CSI\u4f5c\u4e3a\u751f\u7269\u8bc6\u522b\u6280\u672f\u7684\u5b89\u5168\u6027\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u7814\u7a76\u5728\u8bc4\u4f30\u65b9\u6cd5\u3001\u5a01\u80c1\u6a21\u578b\u548c\u5b89\u5168\u6307\u6807\u65b9\u9762\u7684\u7cfb\u7edf\u6027\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u6765\u66b4\u9732\u9690\u85cf\u7684\u98ce\u9669\u96c6\u4e2d\u95ee\u9898\u3002", "motivation": "Wi-Fi CSI\u4f5c\u4e3a\u751f\u7269\u8bc6\u522b\u6280\u672f\u867d\u7136\u88ab\u591a\u6b21\u63d0\u51fa\u5e76\u62a5\u544a\u4e86\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u5b89\u5168\u5c5e\u6027\u3001\u5bf9\u6297\u5f39\u6027\u548c\u65b9\u6cd5\u4e00\u81f4\u6027\u7684\u7cfb\u7edf\u7406\u89e3\uff0c\u9700\u8981\u4ece\u5b89\u5168\u89d2\u5ea6\u8fdb\u884c\u7cfb\u7edf\u5316\u77e5\u8bc6\u6574\u7406\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u5de5\u4f5c\u5728\u611f\u77e5\u57fa\u7840\u8bbe\u65bd\u3001\u4fe1\u53f7\u8868\u793a\u3001\u7279\u5f81\u7ba1\u9053\u3001\u5b66\u4e60\u6a21\u578b\u548c\u8bc4\u4f30\u65b9\u6cd5\u7b49\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u6784\u5efa\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u5b89\u5168\u76f8\u5173\u6307\u6807\uff08\u5982\u6bcf\u7c7bEER\u3001FCS\u548c\u57fa\u5c3c\u7cfb\u6570\uff09\u6765\u63ed\u793a\u4f20\u7edf\u62a5\u544a\u65b9\u6cd5\u9690\u85cf\u7684\u98ce\u9669\u96c6\u4e2d\u95ee\u9898\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u7cfb\u7edf\u6027\u4e0d\u4e00\u81f4\uff1a\u4f9d\u8d56\u805a\u5408\u7cbe\u5ea6\u6307\u6807\u3001\u6709\u9650\u7684FAR/FRR/EER\u62a5\u544a\u3001\u7f3a\u4e4f\u6bcf\u7528\u6237\u98ce\u9669\u5206\u6790\u3001\u5f88\u5c11\u8003\u8651\u5a01\u80c1\u6a21\u578b\u6216\u5bf9\u6297\u53ef\u884c\u6027\u3002\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u4e86\u5305\u62ec\u91cd\u653e\u3001\u51e0\u4f55\u6a21\u4eff\u548c\u73af\u5883\u6270\u52a8\u5728\u5185\u7684\u5177\u4f53\u653b\u51fb\u9762\u3002", "conclusion": "\u672c\u6587\u9610\u660e\u4e86\u5f53\u524dCSI\u751f\u7269\u8bc6\u522b\u7684\u5b89\u5168\u8fb9\u754c\uff0c\u4e3a\u4e25\u683c\u8bc4\u4f30\u3001\u53ef\u91cd\u590d\u5b9e\u9a8c\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u9488\uff0c\u4e3a\u5b89\u5168\u793e\u533a\u63d0\u4f9b\u4e86\u5bf9Wi-Fi CSI\u751f\u7269\u8bc6\u522b\u6280\u672f\u53ca\u5176\u4f5c\u4e3a\u8ba4\u8bc1\u539f\u8bed\u9002\u7528\u6027\u7684\u7ed3\u6784\u5316\u3001\u8bc1\u636e\u9a71\u52a8\u7684\u91cd\u65b0\u8bc4\u4f30\u3002"}}
{"id": "2511.11385", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.11385", "abs": "https://arxiv.org/abs/2511.11385", "authors": ["Faezeh Nasrabadi", "Robert K\u00fcnnemann", "Hamed Nemati"], "title": "Automated Side-Channel Analysis of Cryptographic Protocol Implementations", "comment": null, "summary": "We extract the first formal model of WhatsApp from its implementation by combining binary-level analysis (via CryptoBap) with reverse engineering (via Ghidra) to handle this large closed-source application. Using this model, we prove forward secrecy, identify a known clone-attack against post-compromise security and discover functional gaps between WhatsApp's implementation and its specification. We further introduce a methodology to analyze cryptographic protocol implementations for their resilience to side-channel attacks. This is achieved by extending the CryptoBap framework to integrate hardware leakage contracts into the protocol model, which we then pass to the state-of-the-art protocol prover, DeepSec. This enables a detailed security analysis against both functional bugs and microarchitectural side-channel attacks. Using this methodology, we identify a privacy attack in WhatsApp that allows a side-channel attacker to learn the victim's contacts and confirm a known unlinkability attack on the BAC protocol used in electronic passports.\n  Key contributions include (1) the first formal model of WhatsApp, extracted from its binary, (2) a framework to integrate side-channel leakage contracts into protocol models for the first time, and (3) revealing critical vulnerabilities invisible to specification-based methods.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e8c\u8fdb\u5236\u5206\u6790\u548c\u9006\u5411\u5de5\u7a0b\u6784\u5efa\u4e86WhatsApp\u7684\u9996\u4e2a\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u524d\u5411\u5b89\u5168\u6027\uff0c\u8bc6\u522b\u4e86\u514b\u9686\u653b\u51fb\uff0c\u5e76\u53d1\u73b0\u4e86\u5b9e\u73b0\u4e0e\u89c4\u8303\u4e4b\u95f4\u7684\u529f\u80fd\u5dee\u8ddd\u3002\u540c\u65f6\u5f15\u5165\u4e86\u5c06\u4fa7\u4fe1\u9053\u6cc4\u6f0f\u5408\u7ea6\u96c6\u6210\u5230\u534f\u8bae\u6a21\u578b\u4e2d\u7684\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u89c4\u8303\u65b9\u6cd5\u65e0\u6cd5\u53d1\u73b0\u7684\u4e25\u91cd\u6f0f\u6d1e\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5206\u6790\u5927\u578b\u95ed\u6e90\u5e94\u7528\uff08\u5982WhatsApp\uff09\u7684\u52a0\u5bc6\u534f\u8bae\u5b9e\u73b0\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u9488\u5bf9\u529f\u80fd\u6f0f\u6d1e\u548c\u5fae\u67b6\u6784\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5168\u9762\u5b89\u5168\u5206\u6790\u3002", "method": "\u7ed3\u5408CryptoBap\u4e8c\u8fdb\u5236\u5206\u6790\u548cGhidra\u9006\u5411\u5de5\u7a0b\u63d0\u53d6WhatsApp\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u6269\u5c55CryptoBap\u6846\u67b6\u96c6\u6210\u786c\u4ef6\u6cc4\u6f0f\u5408\u7ea6\uff0c\u5e76\u4f7f\u7528DeepSec\u534f\u8bae\u9a8c\u8bc1\u5668\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86WhatsApp\u7684\u524d\u5411\u5b89\u5168\u6027\uff0c\u8bc6\u522b\u4e86\u5df2\u77e5\u7684\u514b\u9686\u653b\u51fb\uff0c\u53d1\u73b0\u4e86\u5b9e\u73b0\u4e0e\u89c4\u8303\u7684\u529f\u80fd\u5dee\u8ddd\uff0c\u5e76\u8bc6\u522b\u4e86\u5141\u8bb8\u4fa7\u4fe1\u9053\u653b\u51fb\u8005\u83b7\u53d6\u53d7\u5bb3\u8005\u8054\u7cfb\u4eba\u4fe1\u606f\u7684\u9690\u79c1\u653b\u51fb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63ed\u793a\u4f20\u7edf\u89c4\u8303\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u4e3a\u52a0\u5bc6\u534f\u8bae\u5b9e\u73b0\u7684\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\uff0c\u7279\u522b\u662f\u5728\u4fa7\u4fe1\u9053\u653b\u51fb\u9632\u62a4\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.11549", "categories": ["cs.CR", "cs.DB", "cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.11549", "abs": "https://arxiv.org/abs/2511.11549", "authors": ["Shreya Meel", "Sennur Ulukus"], "title": "HetDAPAC: Leveraging Attribute Heterogeneity in Distributed Attribute-Based Private Access Control", "comment": null, "summary": "Verifying user attributes to provide fine-grained access control to databases is fundamental to attribute-based authentication. Either a single (central) authority verifies all the attributes, or multiple independent authorities verify the attributes distributedly. In the central setup, the authority verifies all user attributes, and the user downloads only the authorized record. While this is communication efficient, it reveals all user attributes to the authority. A distributed setup prevents this privacy breach by letting each authority verify and learn only one attribute. Motivated by this, Jafarpisheh~et~al. introduced an information-theoretic formulation, called distributed attribute-based private access control (DAPAC). With $N$ non-colluding authorities (servers), $N$ attributes and $K$ possible values for each attribute, the DAPAC system lets each server learn only the single attribute value that it verifies, and is oblivious to the remaining $N-1$. The user retrieves its designated record, without learning anything about the remaining database records. The goal is to maximize the rate, i.e., the ratio of desired message size to total download size. However, not all attributes are sensitive, and DAPAC's privacy constraints can be too restrictive, negatively affecting the rate. To leverage the heterogeneous privacy requirements of user attributes, we propose heterogeneous (Het)DAPAC, a framework which off-loads verification of $N-D$ of the $N$ attributes to a central server, and retains DAPAC's architecture for the $D$ sensitive attributes. We first present a HetDAPAC scheme, which improves the rate from $\\frac{1}{2K}$ to $\\frac{1}{K+1}$, while sacrificing the privacy of a few non-sensitive attributes. Unlike DAPAC, our scheme entails a download imbalance across servers; we propose a second scheme achieving a balanced per-server download and a rate of $\\frac{D+1}{2KD}$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f02\u6784\u5206\u5e03\u5f0f\u5c5e\u6027\u79c1\u6709\u8bbf\u95ee\u63a7\u5236(HetDAPAC)\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u975e\u654f\u611f\u5c5e\u6027\u9a8c\u8bc1\u96c6\u4e2d\u5316\u5904\u7406\uff0c\u5728\u4fdd\u6301\u654f\u611f\u5c5e\u6027\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u7cfb\u7edf\u6548\u7387\u3002", "motivation": "\u4f20\u7edfDAPAC\u7cfb\u7edf\u5bf9\u6240\u6709\u5c5e\u6027\u91c7\u7528\u76f8\u540c\u7684\u9690\u79c1\u4fdd\u62a4\u7ea7\u522b\uff0c\u4f46\u5e76\u975e\u6240\u6709\u5c5e\u6027\u90fd\u662f\u654f\u611f\u7684\uff0c\u8fd9\u79cd\u7edf\u4e00\u7684\u9690\u79c1\u7ea6\u675f\u4f1a\u964d\u4f4e\u7cfb\u7edf\u6548\u7387\u3002\u4e3a\u4e86\u5229\u7528\u7528\u6237\u5c5e\u6027\u7684\u5f02\u6784\u9690\u79c1\u9700\u6c42\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u7075\u6d3b\u7684\u8bbf\u95ee\u63a7\u5236\u65b9\u6848\u3002", "method": "\u63d0\u51faHetDAPAC\u6846\u67b6\uff0c\u5c06N\u4e2a\u5c5e\u6027\u4e2d\u7684N-D\u4e2a\u975e\u654f\u611f\u5c5e\u6027\u9a8c\u8bc1\u8f6c\u79fb\u5230\u4e2d\u592e\u670d\u52a1\u5668\u5904\u7406\uff0c\u4ec5\u5bf9D\u4e2a\u654f\u611f\u5c5e\u6027\u4fdd\u6301DAPAC\u7684\u5206\u5e03\u5f0f\u9a8c\u8bc1\u67b6\u6784\u3002\u8bbe\u8ba1\u4e86\u4e24\u79cd\u65b9\u6848\uff1a\u4e00\u79cd\u63d0\u9ad8\u6548\u7387\u4f46\u5b58\u5728\u4e0b\u8f7d\u4e0d\u5e73\u8861\uff0c\u53e6\u4e00\u79cd\u5b9e\u73b0\u670d\u52a1\u5668\u95f4\u4e0b\u8f7d\u5e73\u8861\u3002", "result": "\u7b2c\u4e00\u4e2a\u65b9\u6848\u5c06\u901f\u7387\u4ece1/(2K)\u63d0\u9ad8\u52301/(K+1)\uff0c\u7b2c\u4e8c\u4e2a\u65b9\u6848\u5b9e\u73b0\u5e73\u8861\u4e0b\u8f7d\u4e14\u901f\u7387\u4e3a(D+1)/(2KD)\u3002", "conclusion": "HetDAPAC\u6846\u67b6\u901a\u8fc7\u533a\u5206\u654f\u611f\u548c\u975e\u654f\u611f\u5c5e\u6027\u7684\u9690\u79c1\u9700\u6c42\uff0c\u5728\u4fdd\u6301\u654f\u611f\u5c5e\u6027\u9690\u79c1\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u7cfb\u7edf\u6548\u7387\uff0c\u4e3a\u5c5e\u6027\u9a8c\u8bc1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
